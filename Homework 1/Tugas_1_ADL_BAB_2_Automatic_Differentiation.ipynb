{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2.5. Automatic Differentiation.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOZ1QrJ7/APZ84W1poGC0MW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hadinursalim/MK-Applied-Deep-Learning/blob/main/2_5_Automatic_Differentiation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.5.1. A Simple Example"
      ],
      "metadata": {
        "id": "kF6ah0LL7Du_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wREgFq1R7BJQ",
        "outputId": "834ed7f3-e9ca-46e9-ce66-4cc856ed2524"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0., 1., 2., 3.])"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "x = torch.arange(4.0)\n",
        "x"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x.requires_grad_(True)  # Same as `x = torch.arange(4.0, requires_grad=True)`\n",
        "x.grad  # The default value is None"
      ],
      "metadata": {
        "id": "cTKD2fIB7QGo"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = 2 * torch.dot(x, x)\n",
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zalcnIjP7TjH",
        "outputId": "1eed4a3c-43ea-4f9a-9c90-bf51b3928fdc"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(28., grad_fn=<MulBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y.backward()\n",
        "x.grad"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kXZSg8rN7XF3",
        "outputId": "b6e6c460-3546-4faf-f52c-02755d2d77c0"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 0.,  4.,  8., 12.])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x.grad == 4 * x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vhMqd2f67aqs",
        "outputId": "e9bf68db-c0ee-4067-d8a5-b0ec6f644886"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([True, True, True, True])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# PyTorch accumulates the gradient in default, we need to clear the previous\n",
        "# values\n",
        "x.grad.zero_()\n",
        "y = x.sum()\n",
        "y.backward()\n",
        "x.grad"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UPKoQVHN7eP9",
        "outputId": "1ac85a4b-e170-41ea-aff1-3343ce7e1f85"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1., 1., 1., 1.])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.5.2. Backward for Non-Scalar Variables"
      ],
      "metadata": {
        "id": "ogUNZnqp7iqP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Invoking `backward` on a non-scalar requires passing in a `gradient` argument\n",
        "# which specifies the gradient of the differentiated function w.r.t `self`.\n",
        "# In our case, we simply want to sum the partial derivatives, so passing\n",
        "# in a gradient of ones is appropriate\n",
        "x.grad.zero_()\n",
        "y = x * x\n",
        "# y.backward(torch.ones(len(x))) equivalent to the below\n",
        "y.sum().backward()\n",
        "x.grad"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YMe99rtU7j5t",
        "outputId": "8ee2a64e-f6f8-4e7a-8314-4424346b41ca"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0., 2., 4., 6.])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.5.3. Detaching Computation"
      ],
      "metadata": {
        "id": "vs83JFwN7qL3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x.grad.zero_()\n",
        "y = x * x\n",
        "u = y.detach()\n",
        "z = u * x\n",
        "\n",
        "z.sum().backward()\n",
        "x.grad == u"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hNiOJRLg7rWF",
        "outputId": "4ece07d5-303f-4117-e058-d224ca17452e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([True, True, True, True])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x.grad.zero_()\n",
        "y.sum().backward()\n",
        "x.grad == 2 * x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UnZ5lk-P7wbd",
        "outputId": "48551893-f422-4542-c43c-8aed88d65143"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([True, True, True, True])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.5.4. Computing the Gradient of Python Control Flow"
      ],
      "metadata": {
        "id": "iCShEkvn70lm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def f(a):\n",
        "    b = a * 2\n",
        "    while b.norm() < 1000:\n",
        "        b = b * 2\n",
        "    if b.sum() > 0:\n",
        "        c = b\n",
        "    else:\n",
        "        c = 100 * b\n",
        "    return c"
      ],
      "metadata": {
        "id": "u_l_wrUf71cd"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.randn(size=(), requires_grad=True)\n",
        "d = f(a)\n",
        "d.backward()"
      ],
      "metadata": {
        "id": "UQoHJdcO76Jm"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a.grad == d / a"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZF6PGXZR79lN",
        "outputId": "9a644233-01bf-4a3e-fb27-5705e3e77f7d"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(True)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    }
  ]
}
