{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tugas 1 ADL BAB 5.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOSNd2719viju7KFZCmiEAp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hadinursalim/MK-Applied-Deep-Learning/blob/main/Tugas_1_ADL_BAB_5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**5. Deep Learning Computation**"
      ],
      "metadata": {
        "id": "kZNUyIJ48RXc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**5.1. Layers and Blocks**"
      ],
      "metadata": {
        "id": "2KWEO5ur8joQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "\n",
        "net = nn.Sequential(nn.Linear(20, 256), nn.ReLU(), nn.Linear(256, 10))\n",
        "\n",
        "X = torch.rand(2, 20)\n",
        "net(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5HIK4PJ68nl_",
        "outputId": "64b6ff0c-f6a0-48e7-c448-b2cea7477c55"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.1402,  0.2116, -0.1305, -0.0271, -0.1197,  0.0254,  0.0645, -0.2315,\n",
              "          0.2416, -0.0549],\n",
              "        [ 0.0687,  0.1758, -0.0542,  0.0208, -0.1342, -0.1092,  0.0668, -0.2216,\n",
              "          0.1866,  0.0573]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5.1.1. A Custom Block"
      ],
      "metadata": {
        "id": "Fa3NQjSC8ty5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MLP(nn.Module):\n",
        "    # Declare a layer with model parameters. Here, we declare two fully\n",
        "    # connected layers\n",
        "    def __init__(self):\n",
        "        # Call the constructor of the `MLP` parent class `Module` to perform\n",
        "        # the necessary initialization. In this way, other function arguments\n",
        "        # can also be specified during class instantiation, such as the model\n",
        "        # parameters, `params` (to be described later)\n",
        "        super().__init__()\n",
        "        self.hidden = nn.Linear(20, 256)  # Hidden layer\n",
        "        self.out = nn.Linear(256, 10)  # Output layer\n",
        "\n",
        "    # Define the forward propagation of the model, that is, how to return the\n",
        "    # required model output based on the input `X`\n",
        "    def forward(self, X):\n",
        "        # Note here we use the funtional version of ReLU defined in the\n",
        "        # nn.functional module.\n",
        "        return self.out(F.relu(self.hidden(X)))"
      ],
      "metadata": {
        "id": "Ql-6RE6J8v_A"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net = MLP()\n",
        "net(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QF-Sy7Iz8z7J",
        "outputId": "dcf163e9-67c5-4b66-bad5-b5863932f95e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.1352, -0.0683,  0.1013, -0.1185,  0.2178,  0.1565, -0.0246, -0.1210,\n",
              "          0.0130,  0.2316],\n",
              "        [ 0.0794, -0.0356,  0.0027, -0.0960,  0.0167,  0.0062,  0.0625, -0.0695,\n",
              "          0.0865,  0.1772]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5.1.2. The Sequential Block"
      ],
      "metadata": {
        "id": "iUSFeGl485Ty"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MySequential(nn.Module):\n",
        "    def __init__(self, *args):\n",
        "        super().__init__()\n",
        "        for idx, module in enumerate(args):\n",
        "            # Here, `module` is an instance of a `Module` subclass. We save it\n",
        "            # in the member variable `_modules` of the `Module` class, and its\n",
        "            # type is OrderedDict\n",
        "            self._modules[str(idx)] = module\n",
        "\n",
        "    def forward(self, X):\n",
        "        # OrderedDict guarantees that members will be traversed in the order\n",
        "        # they were added\n",
        "        for block in self._modules.values():\n",
        "            X = block(X)\n",
        "        return X"
      ],
      "metadata": {
        "id": "yimlP9VS87UB"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net = MySequential(nn.Linear(20, 256), nn.ReLU(), nn.Linear(256, 10))\n",
        "net(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lzr4yVXW8-SQ",
        "outputId": "6950978d-e3e0-4b9f-bc8f-50eb0135e6eb"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.2170, -0.0175,  0.1394, -0.0796, -0.3128, -0.1706,  0.1061, -0.0453,\n",
              "         -0.0818, -0.0146],\n",
              "        [ 0.1032, -0.0419,  0.0341, -0.1216, -0.2852, -0.2249,  0.0212, -0.0363,\n",
              "         -0.0621,  0.0451]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5.1.3. Executing Code in the Forward Propagation Function"
      ],
      "metadata": {
        "id": "1KcdIQUc9C9_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FixedHiddenMLP(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        # Random weight parameters that will not compute gradients and\n",
        "        # therefore keep constant during training\n",
        "        self.rand_weight = torch.rand((20, 20), requires_grad=False)\n",
        "        self.linear = nn.Linear(20, 20)\n",
        "\n",
        "    def forward(self, X):\n",
        "        X = self.linear(X)\n",
        "        # Use the created constant parameters, as well as the `relu` and `mm`\n",
        "        # functions\n",
        "        X = F.relu(torch.mm(X, self.rand_weight) + 1)\n",
        "        # Reuse the fully-connected layer. This is equivalent to sharing\n",
        "        # parameters with two fully-connected layers\n",
        "        X = self.linear(X)\n",
        "        # Control flow\n",
        "        while X.abs().sum() > 1:\n",
        "            X /= 2\n",
        "        return X.sum()"
      ],
      "metadata": {
        "id": "E8WQQCth9EuP"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net = FixedHiddenMLP()\n",
        "net(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1M0EdJ0p9IZh",
        "outputId": "97941da2-dcce-49de-c52a-7cea261288b3"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.2959, grad_fn=<SumBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class NestMLP(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(nn.Linear(20, 64), nn.ReLU(),\n",
        "                                 nn.Linear(64, 32), nn.ReLU())\n",
        "        self.linear = nn.Linear(32, 16)\n",
        "\n",
        "    def forward(self, X):\n",
        "        return self.linear(self.net(X))\n",
        "\n",
        "chimera = nn.Sequential(NestMLP(), nn.Linear(16, 20), FixedHiddenMLP())\n",
        "chimera(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oB2xQtCe9LLu",
        "outputId": "e46a85c8-9fe9-4096-ffa8-6e1c93b8b183"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.0081, grad_fn=<SumBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**5.2. Parameter Management**"
      ],
      "metadata": {
        "id": "s7MAZpy69SNv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "net = nn.Sequential(nn.Linear(4, 8), nn.ReLU(), nn.Linear(8, 1))\n",
        "X = torch.rand(size=(2, 4))\n",
        "net(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ql78a72_9Vkw",
        "outputId": "84dd2305-b554-4f7e-dea0-179e943e2d47"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.3137],\n",
              "        [0.3180]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5.2.1. Parameter Access"
      ],
      "metadata": {
        "id": "foExifuP9aZW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(net[2].state_dict())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u8YW06OT9cE5",
        "outputId": "4e487c2c-15f8-48f5-8ac2-5f07dbf5914e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OrderedDict([('weight', tensor([[ 0.0977,  0.1111, -0.0430,  0.3244, -0.1837, -0.1704,  0.1212,  0.0625]])), ('bias', tensor([0.2594]))])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5.2.1.1. Targeted Parameters"
      ],
      "metadata": {
        "id": "p4F_6Oa-9fRV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(net[2].bias))\n",
        "print(net[2].bias)\n",
        "print(net[2].bias.data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dntBujW-9hH-",
        "outputId": "cd38e293-a997-4e60-ed08-55a9bb88e44e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'torch.nn.parameter.Parameter'>\n",
            "Parameter containing:\n",
            "tensor([0.2594], requires_grad=True)\n",
            "tensor([0.2594])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "net[2].weight.grad == None"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CbPzgRa69ka2",
        "outputId": "ae952a43-a6fb-4851-b8bf-192e00299417"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5.2.1.2. All Parameters at Once"
      ],
      "metadata": {
        "id": "9Rdp-BDh9nZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(*[(name, param.shape) for name, param in net[0].named_parameters()])\n",
        "print(*[(name, param.shape) for name, param in net.named_parameters()])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n0bURLIM9r22",
        "outputId": "d50afb5e-f9ce-43d2-8334-1b847ebd8d83"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('weight', torch.Size([8, 4])) ('bias', torch.Size([8]))\n",
            "('0.weight', torch.Size([8, 4])) ('0.bias', torch.Size([8])) ('2.weight', torch.Size([1, 8])) ('2.bias', torch.Size([1]))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "net.state_dict()['2.bias'].data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bxCmqb_j9uvP",
        "outputId": "4f8af4e8-8ec0-4f75-cb3c-be7751367d67"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.2594])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5.2.1.3. Collecting Parameters from Nested Blocks"
      ],
      "metadata": {
        "id": "KDOmX0ZP90LG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def block1():\n",
        "    return nn.Sequential(nn.Linear(4, 8), nn.ReLU(),\n",
        "                         nn.Linear(8, 4), nn.ReLU())\n",
        "\n",
        "def block2():\n",
        "    net = nn.Sequential()\n",
        "    for i in range(4):\n",
        "        # Nested here\n",
        "        net.add_module(f'block {i}', block1())\n",
        "    return net\n",
        "\n",
        "rgnet = nn.Sequential(block2(), nn.Linear(4, 1))\n",
        "rgnet(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I9nBD8Vk93zx",
        "outputId": "29b59e7a-61e5-4422-8fec-fdbb8a52f383"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.5383],\n",
              "        [0.5383]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(rgnet)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3KFp4jPh97c5",
        "outputId": "1e9cdd79-e6bf-43c1-91c3-9ebdf0520a4b"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sequential(\n",
            "  (0): Sequential(\n",
            "    (block 0): Sequential(\n",
            "      (0): Linear(in_features=4, out_features=8, bias=True)\n",
            "      (1): ReLU()\n",
            "      (2): Linear(in_features=8, out_features=4, bias=True)\n",
            "      (3): ReLU()\n",
            "    )\n",
            "    (block 1): Sequential(\n",
            "      (0): Linear(in_features=4, out_features=8, bias=True)\n",
            "      (1): ReLU()\n",
            "      (2): Linear(in_features=8, out_features=4, bias=True)\n",
            "      (3): ReLU()\n",
            "    )\n",
            "    (block 2): Sequential(\n",
            "      (0): Linear(in_features=4, out_features=8, bias=True)\n",
            "      (1): ReLU()\n",
            "      (2): Linear(in_features=8, out_features=4, bias=True)\n",
            "      (3): ReLU()\n",
            "    )\n",
            "    (block 3): Sequential(\n",
            "      (0): Linear(in_features=4, out_features=8, bias=True)\n",
            "      (1): ReLU()\n",
            "      (2): Linear(in_features=8, out_features=4, bias=True)\n",
            "      (3): ReLU()\n",
            "    )\n",
            "  )\n",
            "  (1): Linear(in_features=4, out_features=1, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rgnet[0][1][0].bias.data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xqgt7Lcv9-xO",
        "outputId": "c495b2db-54db-48da-a806-0406d823b7fa"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 0.0038,  0.0604,  0.3031, -0.4595,  0.4863, -0.1752, -0.2709,  0.1255])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5.2.2.1. Built-in Initialization"
      ],
      "metadata": {
        "id": "lJpA6H3i-C2m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def init_normal(m):\n",
        "    if type(m) == nn.Linear:\n",
        "        nn.init.normal_(m.weight, mean=0, std=0.01)\n",
        "        nn.init.zeros_(m.bias)\n",
        "net.apply(init_normal)\n",
        "net[0].weight.data[0], net[0].bias.data[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Iqvt7n4-EpK",
        "outputId": "4252c637-0481-49a3-d7eb-75d0136cbe27"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([-0.0031, -0.0005,  0.0026,  0.0038]), tensor(0.))"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def init_constant(m):\n",
        "    if type(m) == nn.Linear:\n",
        "        nn.init.constant_(m.weight, 1)\n",
        "        nn.init.zeros_(m.bias)\n",
        "net.apply(init_constant)\n",
        "net[0].weight.data[0], net[0].bias.data[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SbPPmy_h-Iam",
        "outputId": "64fe8a05-6b60-4e87-ec37-aa49a5f5322d"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([1., 1., 1., 1.]), tensor(0.))"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def xavier(m):\n",
        "    if type(m) == nn.Linear:\n",
        "        nn.init.xavier_uniform_(m.weight)\n",
        "def init_42(m):\n",
        "    if type(m) == nn.Linear:\n",
        "        nn.init.constant_(m.weight, 42)\n",
        "\n",
        "net[0].apply(xavier)\n",
        "net[2].apply(init_42)\n",
        "print(net[0].weight.data[0])\n",
        "print(net[2].weight.data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k0wv1PRk-Lep",
        "outputId": "d6b7253f-e25a-4c19-95b8-ff326533ee44"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-0.4610,  0.1661,  0.1894,  0.2638])\n",
            "tensor([[42., 42., 42., 42., 42., 42., 42., 42.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5.2.2.2. Custom Initialization"
      ],
      "metadata": {
        "id": "ywZsB0VN-PiX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def my_init(m):\n",
        "    if type(m) == nn.Linear:\n",
        "        print(\"Init\", *[(name, param.shape)\n",
        "                        for name, param in m.named_parameters()][0])\n",
        "        nn.init.uniform_(m.weight, -10, 10)\n",
        "        m.weight.data *= m.weight.data.abs() >= 5\n",
        "\n",
        "net.apply(my_init)\n",
        "net[0].weight[:2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pxh-NWfH-SgH",
        "outputId": "5cbb5359-81f6-4a5b-b5c6-7ad270a5f940"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Init weight torch.Size([8, 4])\n",
            "Init weight torch.Size([1, 8])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 6.0176,  9.0298, -9.9016, -9.8020],\n",
              "        [-0.0000,  8.0627, -0.0000,  9.3371]], grad_fn=<SliceBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "net[0].weight.data[:] += 1\n",
        "net[0].weight.data[0, 0] = 42\n",
        "net[0].weight.data[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KhrO-UEO-VuT",
        "outputId": "b038a049-7453-4aff-db0a-17cc7964bcae"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([42.0000, 10.0298, -8.9016, -8.8020])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5.2.3. Tied Parameters"
      ],
      "metadata": {
        "id": "BIszXq2A-aVr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We need to give the shared layer a name so that we can refer to its\n",
        "# parameters\n",
        "shared = nn.Linear(8, 8)\n",
        "net = nn.Sequential(nn.Linear(4, 8), nn.ReLU(),\n",
        "                    shared, nn.ReLU(),\n",
        "                    shared, nn.ReLU(),\n",
        "                    nn.Linear(8, 1))\n",
        "net(X)\n",
        "# Check whether the parameters are the same\n",
        "print(net[2].weight.data[0] == net[4].weight.data[0])\n",
        "net[2].weight.data[0, 0] = 100\n",
        "# Make sure that they are actually the same object rather than just having the\n",
        "# same value\n",
        "print(net[2].weight.data[0] == net[4].weight.data[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W0-vwFTi-cDZ",
        "outputId": "93af3116-e11e-4588-ba4b-cea038ceffb1"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([True, True, True, True, True, True, True, True])\n",
            "tensor([True, True, True, True, True, True, True, True])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**5.3. Deferred Initialization**"
      ],
      "metadata": {
        "id": "h5skCPDh-jSI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "5.3.1. Instantiating a Network"
      ],
      "metadata": {
        "id": "SmbjaGQr-qtk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "net = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Dense(256, activation=tf.nn.relu),\n",
        "    tf.keras.layers.Dense(10),\n",
        "])"
      ],
      "metadata": {
        "id": "AqcYCqIJ-s3S"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "[net.layers[i].get_weights() for i in range(len(net.layers))]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ypv2-LQO-yaf",
        "outputId": "ff5d976d-3d03-4676-a2ed-6205a50d9bae"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[], []]"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = tf.random.uniform((2, 20))\n",
        "net(X)\n",
        "[w.shape for w in net.get_weights()]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aGepM9fz-3fQ",
        "outputId": "29c020ba-bf9a-436f-d291-695e5df6b601"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(20, 256), (256,), (256, 10), (10,)]"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**5.4. Custom Layers**"
      ],
      "metadata": {
        "id": "CqV4S_hU-93m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "\n",
        "\n",
        "class CenteredLayer(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self, X):\n",
        "        return X - X.mean()"
      ],
      "metadata": {
        "id": "olAXmKme_A1_"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "layer = CenteredLayer()\n",
        "layer(torch.FloatTensor([1, 2, 3, 4, 5]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tpTAhi7Q_Dd1",
        "outputId": "5e1accc6-cc0c-4816-9819-ce05c322ea9a"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-2., -1.,  0.,  1.,  2.])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "net = nn.Sequential(nn.Linear(8, 128), CenteredLayer())"
      ],
      "metadata": {
        "id": "PouXxFsg_Gww"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y = net(torch.rand(4, 8))\n",
        "Y.mean()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qdn6dpGa_Jqw",
        "outputId": "d8898ea2-8f31-49d0-d4f3-3c45103e4391"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(-5.5879e-09, grad_fn=<MeanBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5.4.2. Layers with Parameters"
      ],
      "metadata": {
        "id": "8Oe3rcVj_NwY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MyLinear(nn.Module):\n",
        "    def __init__(self, in_units, units):\n",
        "        super().__init__()\n",
        "        self.weight = nn.Parameter(torch.randn(in_units, units))\n",
        "        self.bias = nn.Parameter(torch.randn(units,))\n",
        "    def forward(self, X):\n",
        "        linear = torch.matmul(X, self.weight.data) + self.bias.data\n",
        "        return F.relu(linear)"
      ],
      "metadata": {
        "id": "CaaeMF9q_Qoe"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "linear = MyLinear(5, 3)\n",
        "linear.weight"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YxhDtGQp_U6I",
        "outputId": "93b43fb7-21d4-4e6d-8e09-9953a33c6d01"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([[ 2.2869,  0.8780,  1.4563],\n",
              "        [-0.9687,  0.3553, -0.8966],\n",
              "        [ 0.4340, -0.3011,  0.0769],\n",
              "        [-0.1872, -0.0848, -1.8826],\n",
              "        [ 1.3403,  0.9474,  0.4607]], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "linear(torch.rand(2, 5))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HH5uCqPI_XnO",
        "outputId": "116c8108-fd42-423c-cc1d-093f2ceaa8cb"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.2740, 0.0000, 0.0000],\n",
              "        [1.5881, 0.2225, 0.0000]])"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "net = nn.Sequential(MyLinear(64, 8), MyLinear(8, 1))\n",
        "net(torch.rand(2, 64))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "02FBMjvk_ZyF",
        "outputId": "73111db9-97b8-4014-d541-08818e8c0478"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.],\n",
              "        [0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**5.5. File I/O**"
      ],
      "metadata": {
        "id": "AwuPy0Vv_ggS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "5.5.1. Loading and Saving Tensors"
      ],
      "metadata": {
        "id": "wdK1zx9y_jp2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "\n",
        "x = torch.arange(4)\n",
        "torch.save(x, 'x-file')"
      ],
      "metadata": {
        "id": "l_a_JtkE_lSy"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x2 = torch.load('x-file')\n",
        "x2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Okud0lyV_nzg",
        "outputId": "b0255ffa-1f2b-4475-e2a9-79cd25c8a7b5"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0, 1, 2, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = torch.zeros(4)\n",
        "torch.save([x, y],'x-files')\n",
        "x2, y2 = torch.load('x-files')\n",
        "(x2, y2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nwR_7H-R_ru7",
        "outputId": "0a679f79-d6fe-4580-ce6f-40f61627e35e"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([0, 1, 2, 3]), tensor([0., 0., 0., 0.]))"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mydict = {'x': x, 'y': y}\n",
        "torch.save(mydict, 'mydict')\n",
        "mydict2 = torch.load('mydict')\n",
        "mydict2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ssHgLuse_uVH",
        "outputId": "01861c05-af9d-4e93-b17c-518364505057"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'x': tensor([0, 1, 2, 3]), 'y': tensor([0., 0., 0., 0.])}"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5.5.2. Loading and Saving Model Parameters"
      ],
      "metadata": {
        "id": "MLLh1cAr_xhQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MLP(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.hidden = nn.Linear(20, 256)\n",
        "        self.output = nn.Linear(256, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.output(F.relu(self.hidden(x)))\n",
        "\n",
        "net = MLP()\n",
        "X = torch.randn(size=(2, 20))\n",
        "Y = net(X)"
      ],
      "metadata": {
        "id": "8tHPNwqF_0m4"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(net.state_dict(), 'mlp.params')"
      ],
      "metadata": {
        "id": "g4rI6A_2_3Ho"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clone = MLP()\n",
        "clone.load_state_dict(torch.load('mlp.params'))\n",
        "clone.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yOXtMsRB_55g",
        "outputId": "c044d47a-a6ce-4076-db18-7d75b1105318"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLP(\n",
              "  (hidden): Linear(in_features=20, out_features=256, bias=True)\n",
              "  (output): Linear(in_features=256, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y_clone = clone(X)\n",
        "Y_clone == Y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7cgl4Aar_9Jg",
        "outputId": "18179ab9-b723-47b3-f04c-d2e20e2550d8"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[True, True, True, True, True, True, True, True, True, True],\n",
              "        [True, True, True, True, True, True, True, True, True, True]])"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**5.6. GPUs**"
      ],
      "metadata": {
        "id": "rCoff5yVAC7U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CS_Q_2Z_AGL-",
        "outputId": "8cd770a5-abc2-496d-b254-e5a575df619d"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sat Mar  5 07:34:32 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   48C    P0    28W /  70W |   1648MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5.6.1. Computing Devices"
      ],
      "metadata": {
        "id": "V9L3dWCQAK3B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "torch.device('cpu'), torch.device('cuda'), torch.device('cuda:1')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ALvHds4ANCq",
        "outputId": "d025becb-f2d7-4b4c-ba75-7b2e038f4ab2"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(device(type='cpu'), device(type='cuda'), device(type='cuda', index=1))"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.device_count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CNdFarazAQox",
        "outputId": "fea2a87b-8703-4d1e-c5d5-695d9807a71d"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def try_gpu(i=0):  #@save\n",
        "    \"\"\"Return gpu(i) if exists, otherwise return cpu().\"\"\"\n",
        "    if torch.cuda.device_count() >= i + 1:\n",
        "        return torch.device(f'cuda:{i}')\n",
        "    return torch.device('cpu')\n",
        "\n",
        "def try_all_gpus():  #@save\n",
        "    \"\"\"Return all available GPUs, or [cpu(),] if no GPU exists.\"\"\"\n",
        "    devices = [torch.device(f'cuda:{i}')\n",
        "             for i in range(torch.cuda.device_count())]\n",
        "    return devices if devices else [torch.device('cpu')]\n",
        "\n",
        "try_gpu(), try_gpu(10), try_all_gpus()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NfufhllnAUC-",
        "outputId": "aac6d3cc-c5e6-474d-d892-ab18064a5863"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(device(type='cuda', index=0),\n",
              " device(type='cpu'),\n",
              " [device(type='cuda', index=0)])"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5.6.2. Tensors and GPUs"
      ],
      "metadata": {
        "id": "0Ep09dyUAXLA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.tensor([1, 2, 3])\n",
        "x.device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FQxw5iDfAZaB",
        "outputId": "b61fefae-1578-4fdc-f677-fad12135d460"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5.6.2.1. Storage on the GPU"
      ],
      "metadata": {
        "id": "y4-9G3BVAd8s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = torch.ones(2, 3, device=try_gpu())\n",
        "X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "59lc49bwAf81",
        "outputId": "8904288a-2cd3-4b07-a017-279d2d884de9"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 1., 1.],\n",
              "        [1., 1., 1.]], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y = torch.rand(2, 3, device=try_gpu(1))\n",
        "Y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_67QDFE3AjMv",
        "outputId": "2dbf6aa9-3535-414a-e8a5-7823d603d624"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.2642, 0.0786, 0.2942],\n",
              "        [0.8559, 0.5390, 0.8285]])"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5.6.2.2. Copying"
      ],
      "metadata": {
        "id": "2uiLsA0wApDZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#MASIH BELUM BISA CUDA=0\n",
        "Z = X.cuda(1)\n",
        "print(X)\n",
        "print(Z)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "id": "T33G5MG6BG6O",
        "outputId": "c7401770-3ab5-478f-e604-057aa3e5a69b"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-53-af31d0d5e800>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#MASIH BELUM BISA CUDA=0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mZ\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mZ\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: invalid device ordinal\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Z = X.cuda(1)\n",
        "print(X)\n",
        "print(Z)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "Mbh65IGGBLDq",
        "outputId": "b32a1630-f75f-4073-afb4-bff1b87aee48"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-54-045efdabb693>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mZ\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mZ\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: invalid device ordinal\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y + Z"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        },
        "id": "qQRBi_g5BSJt",
        "outputId": "02891886-e562-4f62-ca76-f592f72c9cec"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-55-e37447af6361>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mY\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mZ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'Z' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Z.cuda(1) is Z"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        },
        "id": "7VkAEy6HBUvt",
        "outputId": "d2a57ccf-2b98-45ab-ef92-9ffeda27d4ed"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-56-a8fc7bdcccac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mZ\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mZ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'Z' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5.6.3. Neural Networks and GPUs"
      ],
      "metadata": {
        "id": "CTnzt6NSBYWw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "net = nn.Sequential(nn.Linear(3, 1))\n",
        "net = net.to(device=try_gpu())"
      ],
      "metadata": {
        "id": "TWJXZu5FBbRV"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C7t6Siw1Bd7h",
        "outputId": "55e2dbd3-21c4-46c3-bbe6-afd774687bc7"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.0389],\n",
              "        [0.0389]], device='cuda:0', grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "net[0].weight.data.device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OXmkd9T_Bgun",
        "outputId": "e6dbd6f1-c0e7-4d92-c2ac-ff40cd4f2545"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**5.6.4. Summary**"
      ],
      "metadata": {
        "id": "-rt-evVlBl7A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can specify devices for storage and calculation, such as the CPU or GPU. By default, data are created in the main memory and then use the CPU for calculations.\n",
        "\n",
        "The deep learning framework requires all input data for calculation to be on the same device, be it CPU or the same GPU.\n",
        "\n",
        "You can lose significant performance by moving data without care. A typical mistake is as follows: computing the loss for every minibatch on the GPU and reporting it back to the user on the command line (or logging it in a NumPy ndarray) will trigger a global interpreter lock which stalls all GPUs. It is much better to allocate memory for logging inside the GPU and only move larger logs."
      ],
      "metadata": {
        "id": "YvPyqpCbBp5s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "joQc9N1jBlmJ"
      }
    }
  ]
}